{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "import time\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "# !pip3 install ../../opencv_contrib_python-3.4.7.28-cp34-cp34m-linux_armv7l.whl\n",
    "# print(\"OpenCV version:\", cv2.__version__)\n",
    "# print(cv2.__file__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the face recognizer and load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = cv2.face.createLBPHFaceRecognizer()\n",
    "recognizer.load('trainer/trainer.yml')\n",
    "cascadePath = \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The names of individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: Ivan: id=1, ...  etc\n",
    "names = ['None', 'Ivan'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture device is open: True\n"
     ]
    }
   ],
   "source": [
    "frame_in_w = 640\n",
    "frame_in_h = 480\n",
    "fps = 15  # Set the frame rate to 15 fps\n",
    "\n",
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, frame_in_w)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_in_h)\n",
    "videoIn.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "print(\"Capture device is open: \" + str(videoIn.isOpened()))\n",
    "scale_factor = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converts a numpy array to an IPython Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_image(a, fmt='jpeg'):\n",
    "    # Convert the numpy array to a PIL image and then to an IPython Image\n",
    "    f = BytesIO() # buffer\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    return IPyImage(data=f.getvalue())\n",
    "\n",
    "prev_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize GPIOControl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pynq/overlay.py:299: UserWarning: Users will not get PARAMETERS / REGISTERS information through TCL files. HWH file is recommended.\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from pynq import Overlay, MMIO\n",
    "\n",
    "class GPIOControl:\n",
    "    def __init__(self, bitstream_file):\n",
    "        self.ol = Overlay(bitstream_file)\n",
    "        self.pmod_base_addr = self.ol.ip_dict[\"Pmod_JA1\"][\"phys_addr\"]\n",
    "        self.led_base_addr = self.ol.ip_dict[\"LEDs\"][\"phys_addr\"]\n",
    "        self.addr_range = self.ol.ip_dict[\"LEDs\"][\"addr_range\"]\n",
    "        self.pmod = MMIO(self.pmod_base_addr, self.addr_range)\n",
    "        self.led = MMIO(self.led_base_addr, self.addr_range)\n",
    "\n",
    "    def turn_on(self):\n",
    "        self.pmod.write(0, 1)\n",
    "        self.led.write(0, 0xFF)\n",
    "\n",
    "    def turn_off(self):\n",
    "        self.pmod.write(0, 0)\n",
    "        self.led.write(0, 0)\n",
    "\n",
    "gpio_control = GPIOControl(\"./gpio.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam released.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while True:\n",
    "        ret, frame = videoIn.read()\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # resize the input frame before processing\n",
    "        frame_resized = cv2.resize(frame_rgb, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "        gray = cv2.cvtColor(frame_resized, cv2.COLOR_RGB2GRAY)\n",
    "        faces = faceCascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        unknown_detected = False\n",
    "        for (x, y, w, h) in faces:\n",
    "            x, y, w, h = int(x/scale_factor), int(y/scale_factor), int(w/scale_factor), int(h/scale_factor)\n",
    "\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            if roi_gray.size == 0:\n",
    "                continue\n",
    "\n",
    "            id, confidence = recognizer.predict(roi_gray)\n",
    "\n",
    "            if (confidence < 100):\n",
    "                id = names[id]\n",
    "                confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "                rectangle_color = (0, 255, 0)  # Green\n",
    "            else:\n",
    "                id = \"unknown\"\n",
    "                confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "                rectangle_color = (255, 0, 0)  # Red\n",
    "                unknown_detected = True\n",
    "\n",
    "            cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), rectangle_color, 2)\n",
    "            cv2.putText(frame_rgb, str(id), (x+5,y-5), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "            cv2.putText(frame_rgb, str(confidence), (x+5,y+h-5), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 1)\n",
    "        if unknown_detected:\n",
    "            gpio_control.turn_on()\n",
    "        else:\n",
    "            gpio_control.turn_off()    \n",
    "        clear_output(wait=True)\n",
    "        display(array_to_image(frame_rgb))\n",
    "        # Limit the processing to the desired frame rate\n",
    "        curr_time = time.time()\n",
    "        elapsed_time = curr_time - prev_time\n",
    "        wait_time = max(1.0/fps - elapsed_time, 0)\n",
    "        time.sleep(wait_time)\n",
    "        prev_time = curr_time\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    videoIn.release()\n",
    "    print(\"Webcam released.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
